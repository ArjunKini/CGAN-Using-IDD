{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ModelTrain.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "j6W8gZ_nsqRB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Run this cell to check how much GPU has been allotted (GPU RAM Free)\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isnâ€™t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VGFvqBRUECvK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#This cell mounts the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M1JUruRu6ifT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Importing necessary packages\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BS0rKBl76urC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def conv_block(in_feat, out_feat, ksize, stride, padding, \n",
        "               activation=nn.LeakyReLU(0.2, inplace=True), use_batchnorm=True):\n",
        "  #Defines convolution block with conv2d, batch normalization and LeakyReLU activation for each block\n",
        "    layers = [nn.Conv2d(in_feat, out_feat, ksize, stride, padding, bias=not use_batchnorm)]\n",
        "    if use_batchnorm:\n",
        "        layers.append(nn.BatchNorm2d(out_feat)) \n",
        "    if activation:\n",
        "        layers.append(activation)\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "class BASIC_D(nn.Module):\n",
        "  #Basic discriminator model for building architecture through recurrence. Uses the Patch GAN architecture.\n",
        "    def __init__(self, nc_in, nc_out, ndf, max_layers=3):\n",
        "        super(BASIC_D, self).__init__()       \n",
        "        main = nn.Sequential()\n",
        "        # input is nc x isize x isize\n",
        "        main.add_module('initial-{0}-{1}'.format(nc_in+nc_out, ndf),\n",
        "                        conv_block(nc_in+nc_out, ndf, 4, 2, 1, use_batchnorm=False))\n",
        "        out_feat = ndf\n",
        "        for layer in range(1, max_layers):\n",
        "            in_feat = out_feat\n",
        "            out_feat = ndf * min(2**layer, 8)\n",
        "            main.add_module('pyramid-{0}-{1}'.format(in_feat, out_feat),\n",
        "                                conv_block(in_feat, out_feat, 4, 2, 1, ))           \n",
        "        in_feat = out_feat\n",
        "        out_feat = ndf*min(2**max_layers, 8)\n",
        "        main.add_module('last-{0}-{1}'.format(in_feat, out_feat),\n",
        "                        conv_block(in_feat, out_feat, 4, 1, 1))\n",
        "        \n",
        "        in_feat, out_feat = out_feat, 1        \n",
        "        main.add_module('output-{0}-{1}'.format(in_feat, out_feat),\n",
        "                        conv_block(in_feat, out_feat, 4, 1, 1, nn.Sigmoid(), False))\n",
        "        self.main = main\n",
        "\n",
        "    def forward(self, a, b):\n",
        "        x = torch.cat((a, b), 1)        \n",
        "        output = self.main(x)                    \n",
        "        return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1SuhnQFG6zGx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class UBlock(nn.Module):\n",
        "  \"\"\" \n",
        "  Defines basic ublock for generator. Unet is an encoder- decoder.\n",
        "  U-Net: [unet_128] (for 128x128 input images) and [unet_256] (for 256x256 input images)\n",
        "  The original U-Net paper: https://arxiv.org/abs/1505.04597\n",
        "  \n",
        "  \"\"\"\n",
        "  \n",
        "    def __init__(self, s, nf_in, max_nf, use_batchnorm=True, nf_out=None, nf_next=None):\n",
        "        super(UBlock, self).__init__()\n",
        "        assert s>=2 and s%2==0\n",
        "        nf_next = nf_next if nf_next else min(nf_in*2, max_nf)\n",
        "        nf_out = nf_out if nf_out else nf_in            \n",
        "        self.conv = nn.Conv2d(nf_in, nf_next, 4, 2, 1, bias=not (use_batchnorm and s>2) )\n",
        "        if s>2:\n",
        "            next_block = [nn.BatchNorm2d(nf_next)] if use_batchnorm else []\n",
        "            next_block += [nn.LeakyReLU(0.2, inplace=True), UBlock(s//2, nf_next, max_nf)]\n",
        "            self.next_block = nn.Sequential(*next_block)\n",
        "        else:\n",
        "            self.next_block = None\n",
        "        convt = [nn.ReLU(), \n",
        "                 nn.ConvTranspose2d(nf_next*2 if self.next_block else nf_next, nf_out,\n",
        "                                        kernel_size=4, stride=2,padding=1, bias=not use_batchnorm)]    \n",
        "        if use_batchnorm:\n",
        "            convt += [nn.BatchNorm2d(nf_out)]        \n",
        "        if s <= 8:\n",
        "            convt += [nn.Dropout(0.5, inplace=True)]\n",
        "        self.convt = nn.Sequential(*convt)  \n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        if self.next_block:\n",
        "            x2 = self.next_block(x)\n",
        "            #Adds skip connections\n",
        "            x = torch.cat((x,x2),1)\n",
        "        return self.convt(x)        \n",
        "\n",
        "\n",
        "def UNET_G(isize, nc_in=3, nc_out=3, ngf=64):\n",
        "    return nn.Sequential(\n",
        "                  UBlock(isize, nc_in, 8*ngf, False, nf_out=nc_out, nf_next=ngf),\n",
        "                  nn.Tanh() )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RzKM6I8J64zJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        m.weight.data.normal_(0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        m.weight.data.normal_(1.0, 0.02)\n",
        "        m.bias.data.fill_(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DqUiEXM367yp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Parameters for our models\n",
        "nc_in -> Number of channels in input (RGB is 3 channels)\n",
        "nc_out -> Number of channels in output\n",
        "ngf -> The number of filters in the last conv layer\n",
        "ndf -> The nuber of filters in the last discriminator layer\n",
        "imageSize -> Input image size (Height and width)\n",
        "batchSize -> Number of images in each batch. Total number of batches per epoch is total_dataset/batch_size\n",
        "lrD and lrG - Learning rates of discriminator and generator respectively\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "nc_in = 3\n",
        "nc_out = 3\n",
        "ngf = 64\n",
        "ndf = 64\n",
        "\n",
        "loadSize = 286\n",
        "imageSize = 256\n",
        "batchSize = 32\n",
        "lrD = 2e-4\n",
        "lrG = 2e-4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tiBqzRv77AuZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "netD = BASIC_D(nc_in, nc_out, ndf)\n",
        "\n",
        "if os.path.exists(\"/content/drive/My Drive/checkpoints/Discy.pt\"):\n",
        "  netD=torch.load(\"/content/drive/My Drive/checkpoints/Discy.pt\")\n",
        "else:\n",
        "  netD.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sLXphEaw7DkJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "netG = UNET_G(imageSize, nc_in, nc_out, ngf)\n",
        "\n",
        "if os.path.exists(\"/content/drive/My Drive/checkpoints/Generator.pt\"):\n",
        "  netG=torch.load(\"/content/drive/My Drive/checkpoints/Generator.pt\")\n",
        "else:\n",
        "  netG.apply(weights_init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qpVrbDeB7Jep",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "inputA = torch.FloatTensor(batchSize, nc_in, imageSize, imageSize)\n",
        "inputB = torch.FloatTensor(batchSize, nc_out, imageSize, imageSize)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6VJ_ghIu7NrR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Remove for CPU usage \n",
        "netD.cuda()\n",
        "netG.cuda()\n",
        "inputA = inputA.cuda()\n",
        "inputB = inputB.cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JsuYjmHZ7Qph",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import glob\n",
        "from random import randint, shuffle\n",
        "\n",
        "#Preprocessing of images in dataset. \n",
        "def resize_image(im,bandwidth=256):\n",
        "    #Resize image to imageSize and remove alpha channel (PNG images have alpha channel, our model does not require this information)\n",
        "    img = im.resize((bandwidth, bandwidth),  Image.ANTIALIAS)\n",
        "    img=np.array(img)/255*2-1\n",
        "    img=img[:,:,:3]\n",
        "    return img\n",
        "def read_image(rc,direction=0):\n",
        "    realimage=Image.open(rc[1])\n",
        "    semantic=Image.open(rc[0])\n",
        "    realimage=resize_image(realimage)\n",
        "    semantic=resize_image(semantic)\n",
        "    if randint(0,1):\n",
        "        realimage=realimage[:,::-1]\n",
        "        semantic=semantic[:,::-1]\n",
        "    if channel_first:\n",
        "        realimage = np.moveaxis(realimage, 2, 0)\n",
        "        semantic = np.moveaxis(semantic, 2, 0)\n",
        "    if direction==0:\n",
        "        return semantic,realimage\n",
        "    else:\n",
        "        return realimage, semantic\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6cCrxcku7YRp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "anuepath=\"/content/drive/My Drive/anue\"\n",
        "TrainCol=glob.glob(anuepath+'/gtFine/train/*/*_labelColors.png')\n",
        "TrainReal=glob.glob(anuepath+'/leftImg8bit/train/*/*_leftImg8bit.png')\n",
        "\n",
        "ValCol=glob.glob(anuepath+'/gtFine/val/*/*_labelColors.png')\n",
        "ValReal=glob.glob(anuepath+'/leftImg8bit/val/*/*_leftImg8bit.png')\n",
        "direction = 0\n",
        "trainAB=list(zip(sorted(TrainCol), sorted(TrainReal)))\n",
        "valAB=list(zip(sorted(ValCol), sorted(ValReal)))\n",
        "\n",
        "assert len(TrainCol) and len(TrainReal)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TxxBsyyO97Xi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def minibatch(dataAB, batchsize, direction=0):\n",
        "    length = len(dataAB)\n",
        "    epoch = i = 0\n",
        "    with open('/content/drive/My Drive/epoch.txt','r') as fp:\n",
        "        epoch=int(fp.read())\n",
        "    tmpsize = None    \n",
        "    while True:\n",
        "        size = tmpsize if tmpsize else batchsize\n",
        "        if i+size > length:\n",
        "            shuffle(dataAB)\n",
        "            i = 0\n",
        "            epoch+=1        \n",
        "        dataA = []\n",
        "        dataB = []\n",
        "        for j in range(i,i+size):\n",
        "            imgA,imgB = read_image(dataAB[j], direction)\n",
        "            dataA.append(imgA)\n",
        "            dataB.append(imgB)\n",
        "        dataA = np.float32(dataA)\n",
        "        dataB = np.float32(dataB)\n",
        "        i+=size\n",
        "        tmpsize = yield epoch, dataA, dataB     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OSPQJfBn98zx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import display\n",
        "def showX(X,epoch,geniter, rows=1):\n",
        "    assert X.shape[0]%rows == 0\n",
        "    int_X = ( (X+1)/2*255).clip(0,255).astype('uint8')\n",
        "    if channel_first:\n",
        "        int_X = np.moveaxis(int_X.reshape(-1,3,imageSize,imageSize), 1, 3)\n",
        "    else:\n",
        "        int_X = int_X.reshape(-1,imageSize,imageSize, 3)\n",
        "    int_X = int_X.reshape(rows, -1, imageSize, imageSize,3).swapaxes(1,2).reshape(rows*imageSize,-1, 3)\n",
        "    \n",
        "    j=Image.fromarray(int_X)\n",
        "    j.save(\"/content/drive/My Drive/output/epoch\"+str(epoch)+\"genit\"+str(geniter)+\".png\")\n",
        "    display(Image.fromarray(int_X))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zYoBrM1W-StB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "channel_first=True\n",
        "channel_axis=1\n",
        "train_batch = minibatch(trainAB, 6, direction=direction)\n",
        "_, trainA, trainB = next(train_batch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-bWWSXuq-hYr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lTuiWC0--hy7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "optimizerD = optim.Adam(netD.parameters(), lr = lrD, betas=(0.5, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr = lrG, betas=(0.5, 0.999))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VpmsnOUA-lGb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "loss = nn.BCELoss()\n",
        "lossL1 = nn.L1Loss()\n",
        "one = None\n",
        "zero = None\n",
        "def netD_train(A, B):    \n",
        "    global one, zero\n",
        "    netD.zero_grad()\n",
        "    output_D_real = netD(A, B)\n",
        "    if one is None:\n",
        "        one = Variable(torch.ones(*output_D_real.size()).cuda())\n",
        "    errD_real = loss(output_D_real, one)\n",
        "    errD_real.backward()\n",
        "\n",
        "    output_G = netG(A)\n",
        "    output_D_fake = netD(A, output_G)\n",
        "    if zero is None:\n",
        "        zero = Variable(torch.zeros(*output_D_fake.size()).cuda())\n",
        "    errD_fake = loss(output_D_fake, zero)\n",
        "    errD_fake.backward()\n",
        "    optimizerD.step()\n",
        "    return (errD_fake.data+errD_real.data)/2,\n",
        "\n",
        "\n",
        "def netG_train(A, B):\n",
        "    global one\n",
        "    netG.zero_grad()d\n",
        "    output_G = netG(A)\n",
        "    output_D_fake = netD(A, output_G)\n",
        "    if one is None:\n",
        "        one = Variable(torch.ones(*output_D_fake.size()).cuda())\n",
        "    errG_fake = loss(output_D_fake, one)    \n",
        "    errG_L1 = lossL1(output_G, B)\n",
        "    errG = errG_fake + 100 * errG_L1\n",
        "    errG.backward()\n",
        "        \n",
        "    optimizerG.step()\n",
        "    return errG_fake.data, errG_L1.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JcIwW1fG-ljh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def V(x):\n",
        "    return Variable(torch.from_numpy(x).cuda())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JYwZs1x7-l8h",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def netG_gen(A):\n",
        "    return np.concatenate([netG(A[i:i+1]).data.cpu().numpy() for i in range(A.size()[0])], axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jIeaeiN1-wjp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pickle\n",
        "from IPython.display import clear_output\n",
        "t0 = time.time()\n",
        "niter = 150\n",
        "gen_iterations = 0\n",
        "errL1 = epoch = errG = 0\n",
        "with open('/content/drive/My Drive/epoch.txt','r') as fp:\n",
        "    epoch=int(fp.read())\n",
        "errL1_sum = errG_sum = errD_sum = 0\n",
        "\n",
        "display_iters = 100\n",
        "val_batch = minibatch(valAB, 6, direction)\n",
        "train_batch = minibatch(trainAB, batchSize, direction)\n",
        "print(train_batch)\n",
        "genLoss=[]\n",
        "discLoss=[]\n",
        "while epoch < niter: \n",
        "    epoch, trainA, trainB = next(train_batch)   \n",
        "    vA, vB = V(trainA), V(trainB)\n",
        "    errD,  = netD_train(vA, vB)\n",
        "    errD_sum +=errD\n",
        "    if gen_iterations%10==0:\n",
        "      print(\"Epoch # \",epoch,\"Minibatch# \",gen_iterations)\n",
        "    \n",
        "    errG, errL1 = netG_train(vA, vB)\n",
        "    errG_sum += errG\n",
        "    errL1_sum += errL1\n",
        "    gen_iterations+=1\n",
        "    if gen_iterations%display_iters==0:\n",
        "        if gen_iterations%(2*display_iters)==0:\n",
        "            torch.save(netG, \"/content/drive/My Drive/checkpoints/Generator.pt\")\n",
        "            torch.save(netD, \"/content/drive/My Drive/checkpoints/Discy.pt\")\n",
        "            with open('/content/drive/My Drive/generatorloss.pickle', 'ab') as fp:\n",
        "              pickle.dump(genLoss, fp)\n",
        "            with open('/content/drive/My Drive/discriminatorloss.pickle', 'ab') as fp:\n",
        "              pickle.dump(discLoss, fp)\n",
        "            genLoss=[]\n",
        "            discLoss=[]\n",
        "            with open('/content/drive/My Drive/epoch.txt','w') as fp:\n",
        "              fp.write(str(epoch))\n",
        "            clear_output()\n",
        "        genLoss.append(errG_sum/display_iters)\n",
        "        discLoss.append(errD_sum/display_iters)\n",
        "        print('[%d/%d][%d] Loss_D: %f Loss_G: %f loss_L1: %f'\n",
        "        % (epoch, niter, gen_iterations, errD_sum/display_iters, \n",
        "           errG_sum/display_iters, errL1_sum/display_iters), time.time()-t0)\n",
        "        _, valA, valB = train_batch.send(6)\n",
        "        vA, vB = V(valA),V(valB)\n",
        "        fakeB = netG_gen(vA)\n",
        "        showX(np.concatenate([valA, valB, fakeB], axis=0),epoch,gen_iterations,3)\n",
        "        \n",
        "        errL1_sum = errG_sum = errD_sum = 0\n",
        "        _, valA, valB = next(val_batch)\n",
        "        fakeB = netG_gen(V(valA))\n",
        "        showX(np.concatenate([valA, valB, fakeB], axis=0),epoch,gen_iterations,3)\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}